# WSL Fixtures Scraper

A Node.js web scraping project to collect Women's Super League (WSL) fixtures data using Playwright.

## ğŸ“‹ Prerequisites

- Node.js (v16.0.0 or higher)
- npm (comes with Node.js)

---

# STEP-BY-STEP GUIDE: How to Run the Scraper

## Step 1: Install Dependencies

Open PowerShell and navigate to the project root directory:

```powershell
cd C:\Users\Naufal\OneDrive\Documents\learn_scraping
```

Install the required npm packages:

```powershell
npm install
```

## Step 2: Install Playwright Browsers

Install the browsers needed for web scraping:

```powershell
npx playwright install
```

This will download Chromium, Firefox, and WebKit browsers (~400MB).

## Step 3: Navigate to the Main Directory

**âš ï¸ CRITICAL:** You MUST run the scraper from inside the `main` directory.

```powershell
cd main
```

Verify you're in the correct directory:

```powershell
pwd
```

**Expected output:** `C:\Users\Naufal\OneDrive\Documents\learn_scraping\main`

## Step 4: Run the Scraper

**âš ï¸ IMPORTANT:** You must run `run-wsl-scraper.js` first to get the seasons data before running any fixture scrapers.

### First Time Setup: Get Seasons Data

Run this first to scrape Tournament seasons metadata:

```powershell
node run-scraper.js
```

This will create the seasons data file that the fixture scrapers need.

### Then Choose Your Scraping Option:

#### Option A: Test Scraper (Recommended First Run)

Tests with just 2 seasons (~2-3 minutes):

```powershell
node test-fixtures.js
```

#### Option B: Full Scraper (All 10 Seasons)

Scrapes all WSL seasons (~15-25 minutes, ~1,300 fixtures):

```powershell
node scrape-all-fixtures.js
```

## Step 5: Check Your Results

Once complete, check the `data` folder for output files:

```powershell
ls data
```

**Expected files:**

- `[League Name]_all_seasons_fixtures_[date].json` - All fixtures (JSON)
- `[League Name]_all_fixtures_[date].csv` - All fixtures (CSV)
- `[League Name]_fixtures_summary_[date].csv` - Summary statistics
- Individual season JSON and CSV files

---

## ğŸ“ Project Structure

```
learn_scraping/
â”œâ”€â”€ package.json                    # Project configuration and dependencies
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ node_modules/                   # Installed dependencies
â””â”€â”€ main/                          # Main application directory
    â”œâ”€â”€ scrape-all-fixtures.js     # Full scraper (all seasons)
    â”œâ”€â”€ test-fixtures.js           # Test scraper (2 seasons)
    â”œâ”€â”€ all-fixtures-scraper.js    # Core fixtures scraping logic
    â”œâ”€â”€ all-seasons-scraper.js     # Seasons data scraper
    â”œâ”€â”€ run-scraper.js         # WSL scraper runner
    â”œâ”€â”€ csvConverter.js            # CSV conversion utilities
    â””â”€â”€ data/                      # Output directory for scraped data
        â”œâ”€â”€ *.json                 # JSON data files
        â””â”€â”€ *.csv                  # CSV data files
```

## ğŸ“Š Output Files

All scraped data is saved in the `main/data/` directory:

## â±ï¸ Expected Runtime

- **Test Scraper:** ~2-3 minutes (2 seasons)
- **Full Scraper:** ~15-25 minutes (all 10 seasons)
- **Expected Output:** ~1,300+ fixtures

## ğŸ¯ Features

- âœ… Scrapes all tournament seasons (2014-2015 to 2024-2025)
- âœ… Extracts comprehensive fixture data (dates, teams, scores, venues, etc.)
- âœ… Concurrent scraping (2 seasons at a time) for efficiency
- âœ… Robust error handling and retry logic
- âœ… Automatic file generation (JSON and CSV formats)
- âœ… Progress tracking and detailed logging
- âœ… Summary statistics generation

## ğŸ“„ Data Source

FBref URL: https://fbref.com/en/comps

## ğŸ“„ License

MIT

## ğŸ‘¤ Author

naksuu24 & Rizal Anditama
